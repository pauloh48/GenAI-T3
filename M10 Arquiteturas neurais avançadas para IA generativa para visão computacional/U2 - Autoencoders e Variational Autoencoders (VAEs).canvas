{
	"nodes":[
		{"id":"d724abef66a2b9c0","type":"text","text":"## Autoencoders ","x":26,"y":142,"width":250,"height":60},
		{"id":"57c3fd85487a56d9","type":"text","text":"- Um **Autoencoder (AE)** √© uma **rede neural profunda** projetada para **comprimir** (codificar) os dados de entrada em uma representa√ß√£o reduzida e depois **reconstruir** (decodificar) a entrada original a partir dessa vers√£o compacta (Bergmann; Stryker, 2024).\n- O objetivo √© **aprender automaticamente** uma **representa√ß√£o latente** (tamb√©m chamada de _gargalo_ ou _bottleneck_) que retenha as **caracter√≠sticas mais importantes** dos dados, eliminando ru√≠do e redund√¢ncia.","x":420,"y":-160,"width":822,"height":140},
		{"id":"169b8bc4a8aa772e","type":"text","text":"* O AE √© composto por **tr√™s partes principais** (Labate, 2024):\n\t1. **Encoder (codificador):** reduz a dimensionalidade dos dados, convertendo-os em um vetor compacto (espa√ßo latente).\n\t2. **C√≥digo latente:** cont√©m as **informa√ß√µes essenciais** da entrada ‚Äî uma representa√ß√£o comprimida.\n\t3. **Decoder (decodificador):** reconstr√≥i os dados originais a partir do c√≥digo latente.\n- O treinamento busca **minimizar o erro entre entrada e sa√≠da**, levando o modelo a:\n    - Capturar **padr√µes essenciais** da imagem.\n    - **Filtrar ru√≠do** e eliminar informa√ß√µes redundantes.","x":420,"y":-2,"width":822,"height":248},
		{"id":"6630b94e401609b5","type":"text","text":" **Import√¢ncia e limita√ß√µes**\n- Embora o AE **n√£o gere novas imagens livremente**, ele √© **fundamental para modelos generativos mais avan√ßados**, como os **VAEs**.\n- Introduz o conceito de **espa√ßo latente organizado**, crucial para a gera√ß√£o controlada e a representa√ß√£o probabil√≠stica de dados.\n- Serve como **ponte conceitual e pr√°tica** entre a **compress√£o de informa√ß√µes** e a **gera√ß√£o de novos exemplos**.","x":420,"y":260,"width":822,"height":213},
		{"id":"24542b458198e707","type":"text","text":"- Explorar **AEs cl√°ssicos e convolucionais**, compreendendo seu papel na extra√ß√£o de padr√µes.\n- Introduzir o **VAE** como extens√£o probabil√≠stica dos AEs.","x":-320,"y":-2,"width":596,"height":100},
		{"id":"708a23da6e421381","type":"text","text":"**O treinamento**:\n- O treinamento √© **n√£o supervisionado** (ou **autossupervisionado**):\n    - A **entrada** e a **sa√≠da esperada** s√£o **iguais**.\n    - A rede aprende **sozinha** a representar os dados de forma eficiente.\n- O modelo √© otimizado para **minimizar o erro de reconstru√ß√£o**, isto √©, a diferen√ßa entre a imagem original e a reconstru√≠da.","x":1400,"y":300,"width":552,"height":226},
		{"id":"b2969f67ecf2a4ab","type":"text","text":"- Durante o treinamento:\n    - O **encoder** aprende a **restringir a informa√ß√£o** ao que √© realmente relevante.\n    - O **decoder** aprende a **reconstruir** os dados a partir dessa representa√ß√£o comprimida.\n- Esse processo obriga o modelo a **descobrir regularidades** e **estruturas internas** nos dados, formando uma base s√≥lida para tarefas futuras como:\n    - **Redu√ß√£o de dimensionalidade.**\n    - **Remo√ß√£o de ru√≠do (denoising).**\n    - **Aprendizado de caracter√≠sticas (feature learning).**","x":2040,"y":300,"width":792,"height":226},
		{"id":"6ead614dbdbcf777","type":"text","text":"![[GenAI T3/M10 Arquiteturas neurais avan√ßadas para IA generativa para vis√£o computacional/assets/U2/ae.png]]","x":1463,"y":-231,"width":427,"height":282},
		{"id":"928d67b26a3d35a0","type":"text","text":"* Representa√ß√£o\n![[GenAI T3/M10 Arquiteturas neurais avan√ßadas para IA generativa para vis√£o computacional/assets/U2/codificacao.png]]","x":1463,"y":117,"width":465,"height":163},
		{"id":"3e7c5477f59cfd5b","type":"text","text":"- O termo **‚Äúlatente‚Äù** vem do latim _latƒìre_, que significa **‚Äúestar escondido‚Äù**.\n- Em **Estat√≠stica**, uma **vari√°vel latente** √© algo **n√£o observ√°vel diretamente**, mas que pode ser **inferido** a partir de dados (ex.: intelig√™ncia, satisfa√ß√£o, clima organizacional).\n- Em **aprendizado profundo**, o **espa√ßo latente** √© o **conjunto de coordenadas internas** que um modelo aprende para **representar a ess√™ncia dos dados**.","x":420,"y":526,"width":822,"height":147},
		{"id":"50d536585986a53b","type":"text","text":"**Met√°fora explicativa**\n- Imagine que voc√™ quer **guardar um √°lbum de fotos no bolso**:\n    - Em vez de levar todas as fotos em tamanho real, faz **esbo√ßos simples** com os tra√ßos essenciais.\n    - Esses esbo√ßos cont√™m o necess√°rio para **reconstruir** as fotos depois.\n    - O **caderno dos esbo√ßos** representa o **espa√ßo latente** ‚Äî n√£o √© a foto original, mas **cont√©m sua ess√™ncia**.","x":620,"y":700,"width":699,"height":218},
		{"id":"988630c8f710d5ee","type":"text","text":"#### Espa√ßo Latente","x":220,"y":760,"width":250,"height":60},
		{"id":"546cbf8fd343a698","type":"text","text":"![[GenAI T3/M10 Arquiteturas neurais avan√ßadas para IA generativa para vis√£o computacional/assets/U2/latente.png]]","x":1427,"y":600,"width":525,"height":363},
		{"id":"97bd176006f17be3","type":"text","text":"- Um **Autoencoder Convolucional (CAE)** √© um tipo de **Autoencoder (AE)** que utiliza **camadas convolucionais (CNNs)** em vez de camadas densas tradicionais (Bergmann; Stryker, 2024).\n- √â especialmente indicado para **dados espaciais**, como **imagens**, que possuem estrutura em grade (pixels organizados em linhas e colunas).\n- As convolu√ß√µes permitem **extrair padr√µes locais e hier√°rquicos**, aproveitando a **estrutura espacial dos dados** e reduzindo o n√∫mero de par√¢metros trein√°veis.","x":566,"y":963,"width":753,"height":163},
		{"id":"c6ffab523511dbb8","type":"text","text":"#### Autoencoder Convolucional","x":220,"y":1096,"width":250,"height":60},
		{"id":"b94406db4e8149a8","type":"text","text":"|**Componente**|**Fun√ß√£o**|\n|---|---|\n|**Encoder convolucional**|Extrai caracter√≠sticas visuais por meio de **camadas convolucionais** intercaladas com **pooling** (ex.: max pooling). Isso reduz gradualmente a resolu√ß√£o da imagem e gera um **mapa de caracter√≠sticas latente** de menor dimens√£o.|\n|**Espa√ßo latente (bottleneck)**|Representa√ß√£o compacta da imagem; cont√©m apenas as informa√ß√µes mais relevantes.|\n|**Decoder convolucional**|Realiza o processo inverso: usa **camadas de upsampling** (interpola√ß√£o ou **convolu√ß√£o transposta**) para aumentar a resolu√ß√£o e **reconstruir a imagem original**.|","x":660,"y":1156,"width":1084,"height":204},
		{"id":"536df5b905683611","type":"text","text":"## Variational Autoencoders (VAEs)","x":-100,"y":1640,"width":294,"height":77},
		{"id":"9a51859faba54e4f","type":"text","text":"- O AE **n√£o foi criado para gerar imagens novas**, mas introduziu a **estrutura base** dos modelos generativos.\n- A ideia de **espa√ßo latente organizado** conecta-se √† no√ß√£o de **distribui√ß√µes de probabilidade** discutida na Unidade I.\n- Quando o modelo passa a usar **camadas convolucionais**, ele aproveita melhor a **estrutura espacial das imagens**.\n- Ao incluir uma **camada probabil√≠stica no espa√ßo latente**, surge o **Variational Autoencoder (VAE)**:\n    - Permite **amostrar pontos do espa√ßo latente** e gerar **novas imagens coerentes**.\n    - Une reconstru√ß√£o precisa e **gera√ß√£o probabil√≠stica**.","x":367,"y":1439,"width":835,"height":220},
		{"id":"e62695f44088e489","type":"text","text":"**Limita√ß√£o do Autoencoder cl√°ssico**\n- O **AE tradicional** aprende a **comprimir** e **reconstruir** dados, mas:\n    - O **espa√ßo latente** resultante **n√£o √© regularizado**.\n    - Os vetores latentes ocupam **regi√µes aleat√≥rias** no espa√ßo.\n    - √â **dif√≠cil gerar novos exemplos coerentes**, pois n√£o h√° uma estrutura probabil√≠stica organizada.\n- Para resolver isso, surge o **Variational Autoencoder (VAE)**, proposto por **Kingma e Welling (2013)**.","x":367,"y":1717,"width":835,"height":203},
		{"id":"fc5223b0a720fef7","type":"text","text":"**Conceito central do VAE**\n- O VAE transforma o AE em um modelo **probabil√≠stico**.\n- Em vez de gerar um √∫nico vetor latente fixo, o **encoder aprende par√¢metros de uma distribui√ß√£o** (geralmente **Normal**) ‚Äî **m√©dia (Œº)** e **desvio padr√£o (œÉ)**.\n- Um vetor latente **z** √© ent√£o **amostrado dessa distribui√ß√£o** e passado ao decoder.\n- O resultado √© um **espa√ßo latente cont√≠nuo, suave e organizado**, onde pequenas mudan√ßas em **z** geram varia√ß√µes plaus√≠veis nas sa√≠das.","x":372,"y":1936,"width":830,"height":224},
		{"id":"0eca2c3f9a8f7645","type":"text","text":"**Benef√≠cios do VAE**\n\n- **Espa√ßo latente cont√≠nuo e bem estruturado**, que permite:\n    - **Gera√ß√£o de novas amostras realistas** (n√£o vistas no treino).\n    - **Interpola√ß√£o (morphing)** entre representa√ß√µes ‚Äî ex.: transformar gradualmente um ‚Äú5‚Äù em um ‚Äú8‚Äù.\n    - **Regulariza√ß√£o natural**, evitando memoriza√ß√£o e overfitting.\n- **Capacidade generativa real**: o VAE pode **reconstruir e criar** novos exemplos plaus√≠veis.","x":372,"y":2200,"width":830,"height":200},
		{"id":"c3c35489a242b455","type":"text","text":"# U2. Autoencoders e Variational Autoencoders (VAEs)","x":-720,"y":732,"width":480,"height":88},
		{"id":"a200e9e85ac0bd9e","type":"text","text":"![[vae_ae.png]]","x":741,"y":2485,"width":557,"height":429},
		{"id":"999d0f302bd26942","type":"text","text":"# Comparativo","x":-596,"y":2495,"width":250,"height":60},
		{"id":"a870facde0066c37","type":"text","text":"- AE: o¬†_encoder_¬†comprime a entrada em um √∫nico ponto¬†_ùëß_¬†no espa√ßo latente, que √© ent√£o decodificado de forma determin√≠stica.\n- VAE: o¬†_encoder_¬†produz par√¢metros estat√≠sticos (como m√©dia e vari√¢ncia) de uma distribui√ß√£o latente; em seguida, um vetor¬†_ùëß_¬†√© amostrado dessa distribui√ß√£o e passado ao¬†_decoder_, incorporando regulariza√ß√£o probabil√≠stica no processo.","x":1390,"y":2582,"width":708,"height":152},
		{"id":"3a90307c48f3b6b3","type":"text","text":"|**Aspecto**|**Autoencoder Cl√°ssico (AE)**|**Variational Autoencoder (VAE)**|\n|---|---|---|\n|**Tipo de codifica√ß√£o**|Determin√≠stica (um ponto fixo no espa√ßo latente)|Probabil√≠stica (distribui√ß√£o gaussiana)|\n|**Espa√ßo latente**|Irregular, sem estrutura definida|Cont√≠nuo, suave e regularizado|\n|**Gera√ß√£o de novos dados**|Dif√≠cil, n√£o natural|Natural, coerente e controlada|\n|**Fun√ß√£o de perda**|Erro de reconstru√ß√£o|Erro de reconstru√ß√£o + regulariza√ß√£o KL|\n|**Capacidade generativa**|Limitada|Alta (gera amostras novas e realistas)|","x":-266,"y":2480,"width":884,"height":294}
	],
	"edges":[
		{"id":"e9d0063374ef83c2","fromNode":"c3c35489a242b455","fromSide":"right","toNode":"d724abef66a2b9c0","toSide":"left"},
		{"id":"a4790389f3d805f4","fromNode":"c3c35489a242b455","fromSide":"right","toNode":"536df5b905683611","toSide":"left"},
		{"id":"a7e144d078c01abd","fromNode":"d724abef66a2b9c0","fromSide":"right","toNode":"169b8bc4a8aa772e","toSide":"left"},
		{"id":"65000777f5095c82","fromNode":"536df5b905683611","fromSide":"right","toNode":"9a51859faba54e4f","toSide":"left"},
		{"id":"5b836812f3c2ef70","fromNode":"c3c35489a242b455","fromSide":"top","toNode":"24542b458198e707","toSide":"left"},
		{"id":"cc8b00cd8a7c7e8b","fromNode":"169b8bc4a8aa772e","fromSide":"right","toNode":"6ead614dbdbcf777","toSide":"left"},
		{"id":"55634e9f0ac3436b","fromNode":"d724abef66a2b9c0","fromSide":"right","toNode":"57c3fd85487a56d9","toSide":"left"},
		{"id":"67ff613cf6d8d46a","fromNode":"169b8bc4a8aa772e","fromSide":"right","toNode":"708a23da6e421381","toSide":"left"},
		{"id":"21eaa36b44598078","fromNode":"708a23da6e421381","fromSide":"right","toNode":"b2969f67ecf2a4ab","toSide":"left"},
		{"id":"931ac80338893362","fromNode":"d724abef66a2b9c0","fromSide":"right","toNode":"6630b94e401609b5","toSide":"left"},
		{"id":"9f66839245e3df4e","fromNode":"169b8bc4a8aa772e","fromSide":"right","toNode":"928d67b26a3d35a0","toSide":"left"},
		{"id":"91ae22c19a672125","fromNode":"d724abef66a2b9c0","fromSide":"bottom","toNode":"988630c8f710d5ee","toSide":"left"},
		{"id":"0bfdd7ea1bd8ea08","fromNode":"988630c8f710d5ee","fromSide":"top","toNode":"3e7c5477f59cfd5b","toSide":"left"},
		{"id":"c39d8b666ebd06c4","fromNode":"988630c8f710d5ee","fromSide":"right","toNode":"50d536585986a53b","toSide":"left"},
		{"id":"d4408d93c1294733","fromNode":"50d536585986a53b","fromSide":"right","toNode":"546cbf8fd343a698","toSide":"left","label":"ex.:"},
		{"id":"bb98a5166ee6489b","fromNode":"d724abef66a2b9c0","fromSide":"bottom","toNode":"c6ffab523511dbb8","toSide":"left"},
		{"id":"5cdbb7de9c2c2549","fromNode":"c6ffab523511dbb8","fromSide":"right","toNode":"97bd176006f17be3","toSide":"left"},
		{"id":"ca65301b8e056441","fromNode":"c6ffab523511dbb8","fromSide":"right","toNode":"b94406db4e8149a8","toSide":"left","label":"Ideia Geral"},
		{"id":"b04bfa00f7afb760","fromNode":"536df5b905683611","fromSide":"right","toNode":"e62695f44088e489","toSide":"left"},
		{"id":"12c1360be1654630","fromNode":"536df5b905683611","fromSide":"right","toNode":"fc5223b0a720fef7","toSide":"left"},
		{"id":"42c357f6f86137d2","fromNode":"536df5b905683611","fromSide":"right","toNode":"0eca2c3f9a8f7645","toSide":"left"},
		{"id":"b88ad98e86c74e33","fromNode":"c3c35489a242b455","fromSide":"bottom","toNode":"999d0f302bd26942","toSide":"left"},
		{"id":"0d502641c2a170ba","fromNode":"999d0f302bd26942","fromSide":"right","toNode":"3a90307c48f3b6b3","toSide":"left"},
		{"id":"398c5540d51d2932","fromNode":"3a90307c48f3b6b3","fromSide":"right","toNode":"a200e9e85ac0bd9e","toSide":"left"},
		{"id":"c11d0d385205c5c4","fromNode":"a200e9e85ac0bd9e","fromSide":"right","toNode":"a870facde0066c37","toSide":"left"}
	]
}