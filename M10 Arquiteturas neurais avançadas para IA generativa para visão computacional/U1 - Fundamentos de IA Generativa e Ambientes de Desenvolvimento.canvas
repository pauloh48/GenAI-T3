{
	"nodes":[
		{"id":"7680bf2aa2ab388c","type":"text","text":"**1. Conceito e propósito da unidade**\n- Apresentar os **conceitos fundamentais da Inteligência Artificial (IA) generativa**.\n- Estabelecer as **bases teóricas e práticas** para estudar e aplicar modelos generativos.","x":240,"y":-960,"width":900,"height":100},
		{"id":"e2cb77eac64b6621","type":"text","text":"**2. Diferença entre IA generativa e IA discriminativa**\n- **IA discriminativa:** classifica, reconhece e diferencia padrões em dados existentes.\n- **IA generativa:** cria **novos dados** (imagens, textos, sons) a partir de padrões aprendidos.\n- Entendimento dessa diferença é essencial para compreender as finalidades e aplicações de cada tipo de modelo.","x":240,"y":-840,"width":900,"height":140},
		{"id":"4cb5d9c16200c7ef","type":"text","text":"**3. Conceitos de visão computacional**\n- Revisão dos fundamentos da **representação digital de imagens**, incluindo:\n    - **Tensores:** estruturas que armazenam dados numéricos das imagens.\n    - **Cores:** sistemas de representação (RGB, escala de cinza).\n    - **Resolução:** quantidade de pixels que define o nível de detalhe de uma imagem.    \n- Esses conceitos são fundamentais para compreender **como modelos generativos “enxergam” e produzem imagens**.","x":240,"y":-680,"width":900,"height":200},
		{"id":"3bd0adbbe78911b5","type":"text","text":"**4. Fundamentos probabilísticos**\n- Revisão de **funções de distribuição de probabilidade**, conectando estatística e IA.\n- Mostra como os modelos usam probabilidades para **gerar novas amostras** (como imagens sintéticas).","x":240,"y":-460,"width":900,"height":100},
		{"id":"eefeae0d8b114642","type":"text","text":"**5. Evolução dos modelos generativos**\n- Linha histórica das principais arquiteturas da IA generativa:\n    - **AEs (Autoencoders):** modelos que aprendem a reconstruir dados.\n    - **VAEs (Variational Autoencoders):** introduzem variabilidade e geração probabilística.\n    - **GANs (Generative Adversarial Networks):** dois modelos competem para criar imagens realistas.\n    - **Modelos de difusão:** técnica moderna que gera imagens de alta qualidade a partir de ruído.\n- Mostra como cada técnica contribuiu para o avanço na **geração artificial de conteúdo visual**.","x":240,"y":-340,"width":900,"height":216},
		{"id":"d202c4443b919957","type":"text","text":" **6. Ferramentas e ambientes de desenvolvimento**\n- Apresentação dos principais **ambientes práticos para IA generativa**:\n    - **Google Colab®** – execução de notebooks em nuvem.\n    - **Hugging Face Hub®** – repositório e compartilhamento de modelos.\n    - **Diffusers®** – biblioteca Python para modelos de difusão.\n    - **Ollama® e outras ferramentas emergentes** – frameworks modernos para execução local de modelos generativos.","x":240,"y":-95,"width":900,"height":220},
		{"id":"59f8b48bf841cebe","type":"text","text":"## O que será visto?","x":-338,"y":-540,"width":250,"height":60},
		{"id":"e316b7fbab4380bd","type":"text","text":"# U1. Fundamentos de IA Generativa e Ambientes de Desenvolvimento","x":-499,"y":320,"width":572,"height":95},
		{"id":"83075f982d4dc504","type":"text","text":"## IA Generativas _vs_ Discriminativas","x":182,"y":460,"width":418,"height":67},
		{"id":"d0dcd99be24dddb9","type":"text","text":"### IA Generativa","x":708,"y":343,"width":250,"height":60},
		{"id":"d473ac1f6d90a64c","type":"text","text":"https://www.datacamp.com/pt/blog/generative-vs-discriminative-models\n![[pip_generativa.png]]","x":1060,"y":203,"width":647,"height":240},
		{"id":"78a6108d191b12f6","type":"text","text":"- Ramo da Inteligência Artificial que busca **criar novos dados ou conteúdos originais** a partir de padrões aprendidos em conjuntos de treinamento.\n- Em vez de apenas reconhecer ou classificar informações, esses modelos **produzem novos exemplos** que se parecem com os dados originais — textos, imagens, áudios, vídeos ou até código.","x":1860,"y":22,"width":880,"height":143},
		{"id":"63f94b43b545d511","type":"text","text":"Exemplo:\n\n- **ChatGPT®** → gera textos, diálogos e explicações em linguagem natural.\n- **DALL·E®** → cria imagens originais a partir de descrições em texto.","x":1860,"y":183,"width":880,"height":120},
		{"id":"10031851f3928eeb","type":"text","text":"**Como funcionam os modelos generativos**\n\n- Aprendem a **distribuição estatística subjacente dos dados de treinamento** — ou seja, os padrões que explicam como os dados “existem” e se organizam.\n- Ao capturar essas regularidades, conseguem **amostrar novos dados** que seguem as mesmas regras do conjunto original, mas **sem copiá-lo diretamente**.\n- Na prática, isso significa que:\n    - Um modelo generativo **não memoriza** exemplos, mas **aprende as relações e estruturas** que os produzem.\n    - Assim, ele pode criar **novos textos, sons ou imagens plausíveis** e coerentes com o mundo real.","x":1860,"y":325,"width":880,"height":275},
		{"id":"cde8c67084830b58","type":"text","text":"**Exemplo ilustrativo:**  \nUm modelo treinado com milhares de paisagens não copia nenhuma delas, mas aprende **como montanhas, céu e luz se combinam** — e então cria novas paisagens que seguem essa lógica.","x":2798,"y":369,"width":782,"height":91},
		{"id":"e23b415fc1887f8b","type":"text","text":"https://www.datacamp.com/pt/blog/generative-vs-discriminative-models\n![[pip_discriminativa.png]]","x":1042,"y":860,"width":665,"height":180},
		{"id":"cf6b9c68fd10b6eb","type":"text","text":"### IA Discriminativa","x":661,"y":840,"width":250,"height":60},
		{"id":"04ade06a3db7af78","type":"text","text":"- **Generativos** aprendem **como os dados são formados**.\n- **Discriminativos** aprendem **como diferenciá-los ou rotulá-los**.","x":445,"y":203,"width":526,"height":56},
		{"id":"7cea9d9af5f1009f","type":"text","text":"* chatGPT\n![[montanha.png]]","x":3760,"y":186,"width":324,"height":456},
		{"id":"34f6bb8f8e29fc18","type":"text","text":"- Seu objetivo é **reconhecer, classificar ou prever** a partir de dados já existentes.\n- Em vez de gerar algo novo, ela **aprende a distinguir entre categorias**.","x":1869,"y":858,"width":863,"height":72},
		{"id":"39640c6c51751f97","type":"text","text":"\n- Exemplos clássicos:\n    - Identificar se uma imagem contém **um gato ou um cachorro**.\n    - Determinar se um e-mail é **spam ou não spam**.\n    - Prever se um cliente **comprará ou não um produto**.","x":1869,"y":950,"width":880,"height":120},
		{"id":"1de6a56a15e81eb0","type":"text","text":"Ex.: Simples: https://colab.research.google.com/drive/1C7pAA4E_PNWW0QAJZorVG1e8YM-rU17q?authuser=1#scrollTo=JZocIus0lQ9V","x":587,"y":980,"width":399,"height":120},
		{"id":"7301c45b2f9d6ae2","type":"text","text":"![[cat_dog.png]]","x":2920,"y":707,"width":318,"height":446},
		{"id":"983d77744004fe29","type":"text","text":"- É o campo da Inteligência Artificial que busca **ensinar máquinas a interpretar e compreender informações visuais** — imagens e vídeos — **de maneira semelhante ao olho e ao cérebro humano**. \n- O objetivo é transformar **dados visuais brutos** em **informações estruturadas**, permitindo que sistemas automatizados **reconheçam padrões e tomem decisões** com base em conteúdo visual.","x":708,"y":1214,"width":880,"height":106},
		{"id":"90f7ba8e6c4e3070","type":"text","text":"**Exemplos de tarefas:**\n- Identificar objetos e rostos;\n- Detectar movimentos;\n- Estimar profundidade ou distância;\n- Reconstruir cenas em 3D;\n- Classificar imagens em categorias (ex.: “cachorro”, “carro”, “paisagem”).","x":1707,"y":1126,"width":593,"height":194},
		{"id":"51fb27e93764e5ba","type":"text","text":"**Usos na Indústria**:\n\n| **Setor**                      | **Aplicação típica**                                                |\n| ------------------------------ | ------------------------------------------------------------------- |\n| **Segurança e autenticação**   | Reconhecimento facial e monitoramento inteligente.                  |\n| **Saúde**                      | Diagnóstico por imagem (radiografias, tomografias, ressonâncias).   |\n| **Transporte**                 | Direção autônoma e sistemas avançados de assistência veicular.      |\n| **Agronegócio**                | Detecção de pragas e avaliação de colheitas via drones.             |\n| **Manufatura e indústria 4.0** | Inspeção automática de produtos e controle de qualidade.            |\n| **Varejo e marketing**         | Análise de comportamento do consumidor e identificação de produtos. |","x":1707,"y":1340,"width":858,"height":231},
		{"id":"09ee0e0a07ad2535","type":"text","text":"**Desafios da Visão Computacional**\n\nInterpretar imagens é uma tarefa complexa porque os dados visuais:\n\n- Possuem **alta dimensionalidade** (milhões de pixels por imagem).\n- Sofrem variações de **iluminação, ângulo, escala e posição**.\n- Podem conter **ruídos**, partes ocultas (oclusões) ou elementos sobreposto","x":691,"y":1354,"width":591,"height":193},
		{"id":"0ae7c521c69fb571","type":"text","text":"**Solução**\n- **Matemática e estatística**, para representar e transformar imagens em números (tensores, matrizes, vetores).\n- **Processamento de sinais**, para filtrar, ajustar e detectar padrões em pixels.\n- **Aprendizado de máquina e redes neurais**, para extrair características (features) relevantes automaticamente.","x":1165,"y":1600,"width":847,"height":140},
		{"id":"f9ec3ba0a277bf80","type":"text","text":"- Em visão computacional, uma **imagem digital** é representada matematicamente como uma **matriz de números** (Jähne, 2005).\n- Cada posição da matriz corresponde a um **pixel**, o menor elemento da imagem.\n- O valor numérico de cada pixel representa sua **cor** (em imagens coloridas) ou **intensidade luminosa** (em imagens em preto e branco).\n- Assim, uma imagem é tratada pelo computador como um **tensor** de dimensões **altura × largura × canais de cor**.","x":1453,"y":1797,"width":1029,"height":128},
		{"id":"5bf1fd76a11f52ce","type":"text","text":"**Representação de cores**\n- O modelo de cor mais comum é o **RGB (Red, Green, Blue)**:\n    - Cada pixel é descrito por **três valores** que indicam a intensidade de vermelho, verde e azul.\n    - Exemplo:\n        - (255, 0, 0) → vermelho puro.\n        - (255, 255, 0) → amarelo.","x":1453,"y":1995,"width":549,"height":240},
		{"id":"a96867119729a2a6","type":"text","text":"- Outros espaços de cor:\n    - **YCbCr** – separa luminância e crominância (usado em compressão de vídeo).\n    - **HSV (Hue, Saturation, Value)** – mais próximo da percepção humana de cor.\n- Em **imagens em escala de cinza**, há apenas **um canal**, indicando o brilho (de 0 = preto a 255 = branco).","x":2054,"y":1995,"width":493,"height":240},
		{"id":"9cbf1c65328be5b3","type":"text","text":"* Tensor (representação em matriz)\n![[matriz.png]]","x":2702,"y":1955,"width":514,"height":358},
		{"id":"388988bd2784cbba","type":"text","text":"* Canais de cores\n![[rgb.png]]","x":2702,"y":1555,"width":514,"height":370},
		{"id":"1e4db63c8b192a6e","type":"text","text":" **Resolução e volume de dados**\n- **Resolução** = número de pixels em largura × altura.\n    - Exemplo: 800×600 → 480.000 pixels; 1920×1080 (Full HD) → +2 milhões de pixels.\n- Resoluções maiores = **mais detalhes visuais**, mas também **maior volume de dados** a processar.\n- Nos primeiros modelos de IA generativa, as imagens tinham **baixa resolução (32×32 ou 64×64)** devido às limitações computacionais.\n- Modelos modernos conseguem gerar **imagens de alta resolução** (512×512, 1024×1024 ou mais).","x":1447,"y":2338,"width":1100,"height":202},
		{"id":"1e3a5c6b7b383149","type":"text","text":"**Dimensionalidade e desafios computacionais**\n\n- Uma imagem colorida de 256×256 pixels tem **256×256×3 = 196.608 dimensões** — um espaço extremamente alto.\n- Essa **alta dimensionalidade** torna o aprendizado mais difícil (problema conhecido como **maldição da dimensionalidade**).\n- Para facilitar o treinamento, é comum **pré-processar** as imagens:\n    - **Normalizar os valores dos pixels** (por exemplo, de 0–255 para 0–1).\n    - **Centralizar os dados** em torno de zero.","x":1447,"y":2560,"width":1100,"height":200},
		{"id":"10e1e26acdfbe548","type":"text","text":" **Espaço latente e eficiência**\n- Modelos generativos modernos (como VAEs e Diffusion Models) não geram imagens **diretamente pixel a pixel**.\n- Em vez disso, eles **trabalham em um espaço latente**, uma **versão comprimida e abstrata** da imagem.\n- O modelo gera essa representação compacta e depois **decodifica** para a imagem completa.\n- Essa abordagem reduz o custo computacional e melhora a eficiência sem perder qualidade perceptível.","x":1447,"y":2780,"width":1100,"height":160},
		{"id":"484170921755f627","type":"text","text":"**Aprendizado da distribuição de imagens**\n\n- O objetivo dos modelos generativos não é memorizar pixels, mas **aprender a distribuição estatística dos dados visuais**.\n    \n- Isso permite **gerar novas imagens** que seguem os mesmos padrões do conjunto de treinamento, mas são **exemplos originais**.\n    \n- Exemplos de modelos baseados nessa ideia: **GANs, VAEs e modelos de difusão**.","x":1447,"y":2960,"width":1100,"height":140},
		{"id":"9241493708812225","type":"text","text":"#### Representação da Imagem","x":660,"y":2288,"width":305,"height":50},
		{"id":"5abd76a2d22c5b2e","type":"text","text":"* https://raphael-abreu.github.io/blog/2021/helloworld/*\n![[GenAI T3/M10 Arquiteturas neurais avançadas para IA generativa para visão computacional/assets/U1/latente.png]]","x":2780,"y":2760,"width":514,"height":353},
		{"id":"42ef343e61b558b8","type":"text","text":"![[normalizacao.png]]","x":2780,"y":2540,"width":640,"height":160},
		{"id":"272d7aa6eaf80dab","type":"text","text":"#### Redes Neurais Convolucionais (CNNs)","x":440,"y":3420,"width":305,"height":62},
		{"id":"6622c9e1ea6ca295","type":"text","text":"##  Visão Computacional","x":182,"y":2048,"width":418,"height":67},
		{"id":"3ad62ef1fd67d593","type":"text","text":"![[cnn.png]]","x":1143,"y":3206,"width":609,"height":276},
		{"id":"f0b6f9540962d50a","type":"text","text":"- **CNNs (Convolutional Neural Networks)** são redes neurais profundas projetadas para processar **dados com estrutura em grade**, como imagens (matrizes de pixels).\n- Seu objetivo é **extrair automaticamente padrões locais** — como bordas, formas e texturas — sem depender de atributos definidos manualmente.\n- Diferem das redes densas tradicionais porque **cada neurônio conecta-se apenas a uma pequena região da entrada**, chamada **campo receptivo**, o que:\n    - Reduz o número de parâmetros;\n    - Aumenta a eficiência e escalabilidade do modelo.","x":1143,"y":3500,"width":1237,"height":160},
		{"id":"d5b2eebd8574b609","type":"text","text":"**Camadas convolucionais**\n- São o **núcleo principal** das CNNs.\n- Utilizam **filtros (kernels)** que percorrem a imagem (operação de **convolução**) para detectar padrões visuais locais.\n- Cada filtro é **aprendido durante o treinamento**, e as camadas sucessivas constroem **representações hierárquicas**:\n    - Camadas iniciais → bordas e texturas simples.\n    - Camadas intermediárias → formas e regiões.\n    - Camadas profundas → objetos e conceitos complexos.\n- Após a convolução, aplica-se normalmente uma **função de ativação não linear** (ex.: **ReLU**) para permitir que a rede capture relações mais complexas.","x":1143,"y":3680,"width":1168,"height":260},
		{"id":"2e4a192493604c57","type":"text","text":"**Camadas de pooling (subamostragem)**\n- **Pooling** reduz a dimensionalidade das representações extraídas.\n- O método mais comum é o **max pooling**, que seleciona o valor máximo em blocos locais de pixels.\n- Benefícios:\n    - Reduz o custo computacional;\n    - Torna o modelo mais **robusto a ruídos e variações espaciais**;\n    - Garante **invariância à posição** dos objetos.","x":1143,"y":3960,"width":1168,"height":220},
		{"id":"1b952582de1372cf","type":"text","text":"**Camadas auxiliares**\n- **Normalização**: estabiliza o aprendizado e acelera a convergência.\n- **Dropout**: desativa aleatoriamente alguns neurônios durante o treinamento, prevenindo **overfitting**.","x":2412,"y":3914,"width":408,"height":226},
		{"id":"ab1153333296e071","type":"text","text":"* Distribuição de probabilidade de temperatura ao meio dia\n![[distr_prob.png]]","x":7366,"y":-3,"width":624,"height":425},
		{"id":"b9142bca826e271f","type":"text","text":"- Uma **função de distribuição de probabilidade** descreve **como a probabilidade se distribui** entre os possíveis valores de uma variável aleatória (Degroot; Schervish, 2012).\n- Em termos simples, é uma **regra matemática que atribui uma chance** a cada evento ou intervalo de resultados.\n- Exemplo: a probabilidade de temperaturas diárias em uma cidade — algumas faixas são **mais prováveis**, outras **raras ou atípicas**.","x":6226,"y":77,"width":854,"height":176},
		{"id":"faaf8aec71c6b176","type":"text","text":"- Em imagens, cada imagem pode ser vista como um ponto em um **espaço de altíssima dimensão** (milhares de pixels).\n- Existe, em teoria, uma **distribuição de probabilidade das imagens reais**, que define quais padrões são **plausíveis** (ex.: fotos reais de flores) e quais são **improváveis** (arranjos aleatórios de pixels).\n- A **IA generativa** tenta **aprender essa distribuição** — ou seja, identificar quais combinações de pixels são mais prováveis de ocorrer em imagens reais.","x":6226,"y":265,"width":851,"height":184},
		{"id":"62b00095ed6292ab","type":"text","text":"**Papel do modelo generativo**\n- O modelo aprende a **aproximar a distribuição dos dados de treinamento**, atribuindo:\n    - **Alta probabilidade** às regiões onde há exemplos reais.\n    - **Baixa probabilidade** onde não há dados reais.\n- Uma vez aprendida essa distribuição, o modelo pode **amostrar novos exemplos**, isto é, **gerar novas imagens** coerentes com o padrão aprendido.\n- Exemplo: um modelo treinado com fotos de flores aprende as **formas, cores e texturas típicas** e cria **novas imagens realistas** a partir desses padrões.","x":6223,"y":457,"width":858,"height":240},
		{"id":"bfd4bb3b9b4a3072","type":"text","text":"|**Modelo**|**Ideia central**|**Papel da probabilidade**|\n|---|---|---|\n|**VAE (Variational Autoencoder)**|Codifica os dados em um **espaço latente probabilístico** e amostra novas instâncias a partir dele.|Aprende e amostra de uma distribuição latente.|\n|**GAN (Generative Adversarial Network)**|Um gerador cria amostras e um discriminador avalia se parecem reais.|O gerador tenta reproduzir a distribuição real dos dados.|\n|**Modelos de Difusão**|Começam com ruído e aprendem a **removê-lo gradualmente** até formar uma imagem coerente.|Inversão de um processo estocástico de ruído.|","x":7366,"y":477,"width":930,"height":233},
		{"id":"339427c8898531ba","type":"text","text":"## Funções de Distribuição de Probabilidade","x":5680,"y":273,"width":339,"height":84},
		{"id":"e4edc6b07f4cf486","type":"text","text":"- Todos os principais modelos generativos (**VAEs, GANs, Difusão**) compartilham o mesmo princípio:\n    \n    - **Aprender ou aproximar a distribuição de probabilidade dos dados reais**.\n        \n    - **Gerar novas instâncias plausíveis** com base nessa distribuição.\n        \n- A evolução da IA generativa nos últimos anos está diretamente ligada ao **aperfeiçoamento dessas representações probabilísticas** em espaços complexos e de alta dimensão.","x":7366,"y":737,"width":930,"height":160},
		{"id":"1460e900efca23f3","type":"text","text":"# U1. Fundamentos de IA Generativa e Ambientes de Desenvolvimento","x":4720,"y":663,"width":572,"height":95},
		{"id":"b526ecebd6f02fec","type":"text","text":"![[GenAI T3/M10 Arquiteturas neurais avançadas para IA generativa para visão computacional/assets/U1/ae.png]]","x":7697,"y":1258,"width":384,"height":358},
		{"id":"35b246b111fc634a","type":"text","text":"um _encoder_ transforma a imagem em um vetor compacto (latente) e um _decoder_ tenta reconstruí-la a partir desse vetor.","x":8157,"y":1393,"width":384,"height":88},
		{"id":"08716d17219d1b3e","type":"text","text":"## Evolução da IA Generativa","x":5672,"y":1308,"width":344,"height":64},
		{"id":"eeaf9c1b92ab9774","type":"text","text":"![[timeline_ia.png]]","x":6223,"y":858,"width":420,"height":514},
		{"id":"5dd5786e1a11b6c6","type":"text","text":"| **Modelo**                                 | **Ideia Central**                                              | **Como Funciona**                                                                                                                | **Vantagens**                                                                               | **Limitações / Desafios**                                                   | **Referências**                                       |\n| ------------------------------------------ | -------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------- | ----------------------------------------------------- |\n| **Autoencoders (AEs)**                     | Comprimir e reconstruir dados                                  | A rede **codifica** a imagem em uma representação **latente compacta** e depois **decodifica** para reconstruí-la.               | - Reduz dimensionalidade- Aprende representações úteis- Estrutura simples e estável         | - Não gera novas amostras com variedade- Tendência a reconstruções borradas | Lecun; Hinton; Goodfellow (2016)                      |\n| **Variational Autoencoders (VAEs)**        | Adicionar componente probabilístico ao AE                      | Impõem uma **distribuição prévia (prior)** sobre o espaço latente e amostram vetores para gerar novas imagens.                   | - Geração probabilística e contínua- Reconstruções coerentes- Treinamento estável           | - Imagens menos nítidas- Compromisso entre qualidade e diversidade          | Kingma; Welling (2014)                                |\n| **Generative Adversarial Networks (GANs)** | Treinar dois modelos em competição (gerador vs. discriminador) | O **gerador** cria imagens e o **discriminador** tenta distinguir reais de falsas; o gerador melhora ao enganar o discriminador. | - Imagens muito nítidas e realistas- Alta fidelidade visual                                 | - Treinamento instável- Problemas como _mode collapse_ (baixa diversidade)  | Goodfellow et al. (2014)                              |\n| **Modelos de Difusão**                     | Gerar imagens removendo gradualmente o ruído                   | O modelo aprende a **inverter um processo de difusão**: começa com ruído puro e o transforma em imagem real passo a passo.       | - Imagens de alta qualidade- Treinamento estável- Controle fino sobre o processo de geração | - Processo lento (muitas etapas)- Alto custo computacional                  | Ho; Jain; Abbeel (2020); Sohl-Dickstein et al. (2015) |","x":6223,"y":1398,"width":1243,"height":436}
	],
	"edges":[
		{"id":"d94ce790cae673a6","fromNode":"e316b7fbab4380bd","fromSide":"top","toNode":"59f8b48bf841cebe","toSide":"left"},
		{"id":"0b71569ce011e70c","fromNode":"59f8b48bf841cebe","fromSide":"right","toNode":"7680bf2aa2ab388c","toSide":"left"},
		{"id":"edb4159c73bd0395","fromNode":"59f8b48bf841cebe","fromSide":"right","toNode":"e2cb77eac64b6621","toSide":"left"},
		{"id":"c46d64327d6d0f4c","fromNode":"59f8b48bf841cebe","fromSide":"right","toNode":"4cb5d9c16200c7ef","toSide":"left"},
		{"id":"1774157ef84c905d","fromNode":"59f8b48bf841cebe","fromSide":"right","toNode":"3bd0adbbe78911b5","toSide":"left"},
		{"id":"59c0932bd5fbcce3","fromNode":"59f8b48bf841cebe","fromSide":"right","toNode":"eefeae0d8b114642","toSide":"left"},
		{"id":"ddf1e2604724ca02","fromNode":"59f8b48bf841cebe","fromSide":"right","toNode":"d202c4443b919957","toSide":"left"},
		{"id":"95775d7486215e53","fromNode":"e316b7fbab4380bd","fromSide":"right","toNode":"83075f982d4dc504","toSide":"left"},
		{"id":"eb6cdf7638ef26a6","fromNode":"83075f982d4dc504","fromSide":"right","toNode":"d0dcd99be24dddb9","toSide":"left"},
		{"id":"bb2b9fb35dfafbd4","fromNode":"83075f982d4dc504","fromSide":"right","toNode":"cf6b9c68fd10b6eb","toSide":"left"},
		{"id":"272839ea185113c7","fromNode":"d0dcd99be24dddb9","fromSide":"right","toNode":"d473ac1f6d90a64c","toSide":"left"},
		{"id":"5c44895939b1bdba","fromNode":"cf6b9c68fd10b6eb","fromSide":"right","toNode":"e23b415fc1887f8b","toSide":"left"},
		{"id":"4c3aa32afca2fd11","fromNode":"d473ac1f6d90a64c","fromSide":"right","toNode":"78a6108d191b12f6","toSide":"left"},
		{"id":"4d72e1a9f46ecdf6","fromNode":"d473ac1f6d90a64c","fromSide":"right","toNode":"63f94b43b545d511","toSide":"left"},
		{"id":"4927ba34298783b5","fromNode":"d473ac1f6d90a64c","fromSide":"right","toNode":"10031851f3928eeb","toSide":"left"},
		{"id":"42907e9b761c7d01","fromNode":"10031851f3928eeb","fromSide":"right","toNode":"cde8c67084830b58","toSide":"left"},
		{"id":"e0b1a736b081d89f","fromNode":"e23b415fc1887f8b","fromSide":"right","toNode":"34f6bb8f8e29fc18","toSide":"left"},
		{"id":"bdd87f321072f9d2","fromNode":"e23b415fc1887f8b","fromSide":"right","toNode":"39640c6c51751f97","toSide":"left"},
		{"id":"d0fd1d9879201ac7","fromNode":"83075f982d4dc504","fromSide":"top","toNode":"04ade06a3db7af78","toSide":"left"},
		{"id":"5cca8f6c2c8c151f","fromNode":"cde8c67084830b58","fromSide":"right","toNode":"7cea9d9af5f1009f","toSide":"left"},
		{"id":"b4c2f43d657cd44d","fromNode":"83075f982d4dc504","fromSide":"bottom","toNode":"1de6a56a15e81eb0","toSide":"left"},
		{"id":"27bcc1267ba4600e","fromNode":"39640c6c51751f97","fromSide":"right","toNode":"7301c45b2f9d6ae2","toSide":"left"},
		{"id":"438ac740e8fa53bc","fromNode":"e316b7fbab4380bd","fromSide":"bottom","toNode":"6622c9e1ea6ca295","toSide":"left"},
		{"id":"2a4bb5c728d519d9","fromNode":"6622c9e1ea6ca295","fromSide":"top","toNode":"983d77744004fe29","toSide":"left"},
		{"id":"aa8cccc195b1fe63","fromNode":"983d77744004fe29","fromSide":"right","toNode":"90f7ba8e6c4e3070","toSide":"left"},
		{"id":"2301e566cfc5e947","fromNode":"983d77744004fe29","fromSide":"right","toNode":"51fb27e93764e5ba","toSide":"left"},
		{"id":"75405c51ee4f40a9","fromNode":"6622c9e1ea6ca295","fromSide":"top","toNode":"09ee0e0a07ad2535","toSide":"left"},
		{"id":"fc7101f4346990a9","fromNode":"09ee0e0a07ad2535","fromSide":"bottom","toNode":"0ae7c521c69fb571","toSide":"left"},
		{"id":"bbd71da7dcc52f84","fromNode":"6622c9e1ea6ca295","fromSide":"bottom","toNode":"9241493708812225","toSide":"left"},
		{"id":"1cbbfd5cb3048876","fromNode":"6622c9e1ea6ca295","fromSide":"bottom","toNode":"272d7aa6eaf80dab","toSide":"left"},
		{"id":"e5f63c31fad87454","fromNode":"9241493708812225","fromSide":"right","toNode":"f9ec3ba0a277bf80","toSide":"left"},
		{"id":"e9350ca832baed76","fromNode":"9241493708812225","fromSide":"right","toNode":"5bf1fd76a11f52ce","toSide":"left"},
		{"id":"fa9b61acc0b9f4b2","fromNode":"5bf1fd76a11f52ce","fromSide":"right","toNode":"a96867119729a2a6","toSide":"left"},
		{"id":"0ce1ad9096be1d80","fromNode":"f9ec3ba0a277bf80","fromSide":"right","toNode":"388988bd2784cbba","toSide":"left"},
		{"id":"ecadcb53dbd250fd","fromNode":"f9ec3ba0a277bf80","fromSide":"right","toNode":"9cbf1c65328be5b3","toSide":"left"},
		{"id":"ad3ee91af3eab5eb","fromNode":"9241493708812225","fromSide":"right","toNode":"1e4db63c8b192a6e","toSide":"left"},
		{"id":"484aa4bebb127745","fromNode":"9241493708812225","fromSide":"right","toNode":"1e3a5c6b7b383149","toSide":"left"},
		{"id":"ee68268e36e62984","fromNode":"9241493708812225","fromSide":"right","toNode":"10e1e26acdfbe548","toSide":"left"},
		{"id":"edc1f406de9d96e2","fromNode":"9241493708812225","fromSide":"right","toNode":"484170921755f627","toSide":"left"},
		{"id":"4b21b10f47c838c2","fromNode":"10e1e26acdfbe548","fromSide":"right","toNode":"5abd76a2d22c5b2e","toSide":"left","label":"espaço latente"},
		{"id":"5865d47d943261f4","fromNode":"1e3a5c6b7b383149","fromSide":"right","toNode":"42ef343e61b558b8","toSide":"left","label":"normalização"},
		{"id":"61d12bf7caf5a268","fromNode":"272d7aa6eaf80dab","fromSide":"right","toNode":"3ad62ef1fd67d593","toSide":"left"},
		{"id":"a8390f99d0139427","fromNode":"272d7aa6eaf80dab","fromSide":"right","toNode":"f0b6f9540962d50a","toSide":"left"},
		{"id":"7836428dfea2f024","fromNode":"272d7aa6eaf80dab","fromSide":"right","toNode":"d5b2eebd8574b609","toSide":"left"},
		{"id":"3f55a8bd0d261433","fromNode":"2e4a192493604c57","fromSide":"right","toNode":"1b952582de1372cf","toSide":"left"},
		{"id":"38578f2816afdaf7","fromNode":"272d7aa6eaf80dab","fromSide":"right","toNode":"2e4a192493604c57","toSide":"left"},
		{"id":"f0ab68cda755c227","fromNode":"1460e900efca23f3","fromSide":"right","toNode":"339427c8898531ba","toSide":"left"},
		{"id":"3b0ab6a820ac1e28","fromNode":"339427c8898531ba","fromSide":"right","toNode":"b9142bca826e271f","toSide":"left"},
		{"id":"c53d2b89f8c49887","fromNode":"b9142bca826e271f","fromSide":"right","toNode":"ab1153333296e071","toSide":"left"},
		{"id":"9008bb91ded1fea0","fromNode":"339427c8898531ba","fromSide":"right","toNode":"faaf8aec71c6b176","toSide":"left"},
		{"id":"f645f4deb87b9511","fromNode":"62b00095ed6292ab","fromSide":"right","toNode":"bfd4bb3b9b4a3072","toSide":"left","label":"Alguns modelos"},
		{"id":"69dae95e10cc4393","fromNode":"62b00095ed6292ab","fromSide":"right","toNode":"e4edc6b07f4cf486","toSide":"left"},
		{"id":"b05083eec344bd65","fromNode":"08716d17219d1b3e","fromSide":"right","toNode":"eeaf9c1b92ab9774","toSide":"left"},
		{"id":"9fdac6e32dfd1175","fromNode":"1460e900efca23f3","fromSide":"right","toNode":"08716d17219d1b3e","toSide":"left"},
		{"id":"f1f79dc7474f398f","fromNode":"08716d17219d1b3e","fromSide":"right","toNode":"5dd5786e1a11b6c6","toSide":"left"},
		{"id":"09ca868c71dc8939","fromNode":"5dd5786e1a11b6c6","fromSide":"right","toNode":"b526ecebd6f02fec","toSide":"left","label":"AE"},
		{"id":"a8b2a5c11622530d","fromNode":"b526ecebd6f02fec","fromSide":"right","toNode":"35b246b111fc634a","toSide":"left"}
	]
}