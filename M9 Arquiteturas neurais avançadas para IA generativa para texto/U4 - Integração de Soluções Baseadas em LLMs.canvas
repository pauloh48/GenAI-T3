{
	"nodes":[
		{"id":"9c03cec79b9abce8","type":"text","text":"# U4. Integração de Soluções Baseadas em LLMs","x":-539,"y":-86,"width":419,"height":86},
		{"id":"2fbb270069221310","type":"text","text":"**Objetivo:** \n* Fazer com que LLMs agreguem valor real em contextos práticos.\n* Necessário **integração** eficiente com sistemas existentes e capacidade de **escalar** conforme o uso cresce.","x":-180,"y":-260,"width":527,"height":143},
		{"id":"f1a3b028f89918e7","type":"text","text":"## Como fazer a Integração?","x":2240,"y":-944,"width":339,"height":76},
		{"id":"3ac4aa4caf968ae0","type":"text","text":"1. **Integração de LLMs**\n![[integracao.png]]","x":703,"y":-400,"width":317,"height":212},
		{"id":"85cc6196372e160a","type":"text","text":"- **Definição:** é o processo de **incorporar o LLM** a um sistema, aplicativo ou fluxo de trabalho.\n- **Meta:** garantir que o modelo opere de forma coordenada, estável e eficiente, agregando valor real ao sistema sem comprometer desempenho ou usabilidade.\n","x":1220,"y":-600,"width":740,"height":91},
		{"id":"84a1e895d7a86c1f","type":"text","text":"- **Desafios comuns:**\n    -  **Integração técnica e compatibilidade:** adaptar APIs, formatos de dados e fluxos de comunicação entre o LLM e os sistemas já existentes.\n\t- **Gerenciamento de latência e desempenho:** garantir respostas rápidas, mesmo com alto volume de requisições.\n\t- **Segurança e privacidade dos dados:** proteger informações sensíveis durante o envio e processamento de dados pelo modelo.\n\t- **Controle de custos e escalabilidade:** otimizar o uso de recursos e monitorar o consumo de tokens ou chamadas de API para manter a solução economicamente viável.","x":1220,"y":-473,"width":740,"height":253},
		{"id":"d5be64ff83fa15eb","type":"text","text":"\n- Garantir **compatibilidade** com os sistemas existentes.\n- Monitorar **desempenho e latência** durante o uso.\n- Implementar **segurança e controle de acesso**.\n- Validar continuamente os **resultados gerados** pelo modelo.","x":3157,"y":-729,"width":320,"height":220},
		{"id":"b463bba0c4f9e5ee","type":"text","text":" 2. **Escalabilidade**\n![[escalabilidade.png]]","x":703,"y":440,"width":337,"height":212},
		{"id":"9c2fa95ead834469","type":"text","text":"\n\n- **Definição:** capacidade do sistema de **crescer e processar maior número de requisições** sem comprometer o desempenho, a estabilidade ou a qualidade das respostas.\n- **Meta:** garantir que as soluções **atendam mais usuários simultaneamente**, mantendo **baixa latência** e **custos controlados**, mesmo em situações de alta demanda.\n","x":1220,"y":463,"width":740,"height":117},
		{"id":"61d0af47454358d7","type":"text","text":"- **Desafios comuns:**\n    - **Gerenciar custos computacionais:** controlar o uso de GPU, tokens e requisições para evitar desperdício.\n    - **Manter eficiência em larga escala:** aplicar cache, paralelização e balanceamento de carga para otimizar o desempenho.\n    - **Adotar infraestrutura elástica:** integrar com plataformas de nuvem e containers (como Kubernetes ou Docker) para ajustar recursos conforme a demanda.\n    - **Garantir estabilidade e segurança:** prevenir gargalos, falhas e degradação do serviço durante picos de uso.","x":1220,"y":622,"width":720,"height":238},
		{"id":"8211ffad4f170546","type":"text","text":"# U5. Escalabilidade de soluções baseadas em LLMs. ","x":2160,"y":719,"width":440,"height":101},
		{"id":"5ff28880d4e86573","type":"text","text":" **Ferramentas e plataformas**\n\n- **Serviços de nuvem:** plataformas como **AWS®, Google Cloud® e Azure®** permitem hospedar e gerenciar modelos de IA com **escalabilidade** e **alta disponibilidade**.\n    \n- Essas plataformas também oferecem **monitoramento automático**, **balanceamento de carga** e **recursos para atualização contínua**.","x":3363,"y":-58,"width":685,"height":156},
		{"id":"cc32d62a35e4182d","type":"text","text":"**Objetivo:** disponibilizar o LLM em **produção** para que possa ser **utilizado pelos usuários finais** de forma estável, segura e eficiente.","x":2688,"y":-80,"width":588,"height":83},
		{"id":"72482dc5e39728e8","type":"text","text":" **Etapas principais do deploy**\n\n- **Otimização do modelo:** ajustar o LLM para o ambiente de produção, reduzindo tamanho, melhorando velocidade e eficiência.\n- **Configuração da infraestrutura:** preparar **servidores ou serviços em nuvem** para suportar o volume esperado de tráfego e requisições.\n- **Segurança e confiabilidade:** implementar políticas de acesso seguro, autenticação e controle de uso para proteger dados e evitar falhas.","x":2682,"y":21,"width":594,"height":217},
		{"id":"d52c6352ff3989b1","type":"text","text":"## Deploy de Soluções para Usuários Finais","x":2251,"y":-14,"width":317,"height":71},
		{"id":"386696c56bd4b5b4","type":"text","text":"**Boas práticas:**\n![[praticas.png]]","x":2682,"y":-764,"width":360,"height":300},
		{"id":"1b3b62266ceea6d5","type":"text","text":"**Etapas principais da integração:**\n- **Planejamento arquitetural:** definir **onde e como** o LLM será inserido na infraestrutura existente.\n- **Escolha da abordagem de integração:** selecionar o **método mais adequado** conforme a arquitetura do sistema.","x":2725,"y":-1253,"width":588,"height":169},
		{"id":"c8b85dc406f0b4db","type":"text","text":"**Abordagem mais comum:**\n- **Uso de APIs:** permite que o LLM seja **acessado por outros componentes** do sistema de forma padronizada, facilitando a comunicação e a manutenção.","x":2725,"y":-1064,"width":588,"height":125},
		{"id":"8283998a61868de1","type":"text","text":"## Integração de _LLMs_ utilizando _Applications_ _Programming_ _Interface_","x":3803,"y":-1674,"width":417,"height":113},
		{"id":"61bd20a38942338b","type":"text","text":"## Integração de _LLMs_ com Plataformas _Low-code_","x":3803,"y":-700,"width":417,"height":120},
		{"id":"b5e0deb1d605f15c","type":"text","text":"- **Como funciona:**\n    - Usuários interagem com diferentes modelos (eles são anônimo para que o usuário não seja enviesado) e votam nas respostas mais coerentes e naturais.\n    - O **ranking** reflete o **desempenho médio** dos modelos em situações de uso prático — quanto **menor o número da posição**, **melhor a performance**.","x":7640,"y":-1763,"width":803,"height":140},
		{"id":"d13a14cdd7890ae8","type":"text","text":"- **Importância:**\n    - É uma referência útil para escolher o modelo mais adequado a **aplicações conversacionais**.\n    - Contudo, o desempenho pode **variar conforme o tipo de tarefa** (por exemplo: resumo, tradução, geração de código etc.).","x":7640,"y":-1603,"width":803,"height":120},
		{"id":"f6366fe5e4f9cdd3","type":"text","text":"- **Definição:**\n    - O custo por 1 milhão de tokens representa **quanto se paga pelo processamento de entrada e saída** nas APIs de LLMs.\n    - Esse valor é **crucial para empresas e desenvolvedores** que precisam lidar com **grandes volumes de dados**.\n        ","x":7640,"y":-1413,"width":803,"height":140},
		{"id":"b5cc347a4027767e","type":"text","text":"\n- **Relação custo × desempenho:**\n    - **Modelos mais potentes** (com maior capacidade e precisão) tendem a ser **mais caros**.\n    - **Modelos mais simples** são **mais baratos**, indicados para tarefas de uso intenso ou respostas curtas.\n    - A escolha depende do **equilíbrio entre performance, contexto e orçamento**.","x":7640,"y":-1253,"width":803,"height":140},
		{"id":"085056ca3f8c2b87","type":"text","text":"**Comparativo entre modelos (Chatbot Arena® (Performance):**\n\n| Posição | Modelo                            | Observações                                            |\n| ------- | --------------------------------- | ------------------------------------------------------ |\n| 1º      | **Gemini 2.5 Pro (Google)**       | Melhor desempenho geral                                |\n| 2º      | **Grok 3 Beta (xAI)**             | Boa interação e equilíbrio                             |\n| 3º      | **o3 (OpenAI)**                   | Geração longa e precisa                                |\n| 4º      | **Gemini 2.5 Flash (Google)**     | Eficiência e baixo custo                               |\n| 8º      | **o4-mini (OpenAI)**              | Bom custo-benefício                                    |\n| 8º      | **DeepSeek R1 (DeepSeek)**        | Econômico, desempenho médio                            |\n| 24º     | **Claude 3.7 Sonnet (Anthropic)** | Boa capacidade, mas desempenho inferior em conversação |","x":8579,"y":-1903,"width":801,"height":320},
		{"id":"40e5032d08173b9d","type":"text","text":"**Comparativo entre modelos (Custo por 1 Milhão de Tokens):**\n\n| Modelo                            | Custo      | Observações                        |\n| --------------------------------- | ---------- | ---------------------------------- |\n| **Gemini 2.5 Flash (Google)**     | **$0.15**  | Mais acessível e eficiente         |\n| **DeepSeek R1 (DeepSeek)**        | $0.55      | Bom custo-desempenho               |\n| **o4-mini (OpenAI)**              | $1.10      | Potente e econômico                |\n| **Gemini 2.5 Pro (Google)**       | $2.50      | Alta performance, custo moderado   |\n| **Grok 3 Beta (xAI)**             | $3.00      | Equilíbrio entre custo e qualidade |\n| **Claude 3.7 Sonnet (Anthropic)** | $3.00      | Boa capacidade, custo médio        |\n| **o3 (OpenAI)**                   | **$10.00** | Modelo premium, custo elevado      |","x":8579,"y":-1413,"width":801,"height":320},
		{"id":"3519913edaf4ad06","type":"text","text":"- **Definição:**\n    - Indica o **tamanho máximo da resposta** que o LLM pode gerar em uma única interação.\n    - Assim como a entrada, a **saída do modelo também é formada por tokens**, que são depois convertidos em texto legível pela API.","x":7640,"y":-2337,"width":803,"height":110},
		{"id":"a6500630c37cd2be","type":"text","text":"- **Importância:**\n    - Modelos com maior limite de saída são ideais para **respostas longas e detalhadas**, como **relatórios, análises extensas ou explicações complexas**.\n    - Limites menores são mais adequados para **respostas diretas e curtas**, otimizando tempo e custo.\n        ","x":7640,"y":-2209,"width":803,"height":122},
		{"id":"4afd0a06d45a6e83","type":"text","text":"\n- **Aplicações práticas:**\n    - **Alta capacidade:** geração de textos completos, artigos, resumos longos ou conteúdo multimodal.\n    - **Baixa capacidade:** chatbots rápidos, perguntas curtas e respostas objetivas.","x":7640,"y":-2068,"width":803,"height":85},
		{"id":"33b1a8336066a3c1","type":"text","text":"Ex. Tokenização\n* Cada cor representa um token\n![[token_ex.png]]","x":8579,"y":-3156,"width":495,"height":356},
		{"id":"685ca05af6bdcf4c","type":"text","text":"**Comparativo entre modelos (Janela de Contexto):**\n\n| Modelo                              | Janela de Contexto (tokens) | Observação                        |\n| ----------------------------------- | --------------------------- | --------------------------------- |\n| **Gemini 2.5 Pro / Flash (Google)** | **1.048.576**               | Maior capacidade geral            |\n| **o3 / o4-mini (OpenAI)**           | 200.000                     | Alto desempenho e compatibilidade |\n| **Claude 3.7 Sonnet (Anthropic)**   | 200.000                     | Boa retenção de contexto          |\n| **Grok 3 Beta (xAI)**               | 131.072                     | Capacidade intermediária          |\n| **DeepSeek R1 (DeepSeek)**          | 128.000                     | Menor entre os listados           |","x":8579,"y":-2761,"width":801,"height":266},
		{"id":"63851007ca1c58e9","type":"text","text":"**Comparativo entre modelos (Máximo de Tokens de Saída):**\n\n| Modelo                              | Tokens de Saída Máx. | Característica                |\n| ----------------------------------- | -------------------- | ----------------------------- |\n| **o3 / o4-mini (OpenAI)**           | **100.000**          | Maior capacidade de geração   |\n| **Gemini 2.5 Pro / Flash (Google)** | 65.536               | Alta qualidade e velocidade   |\n| **Claude 3.7 Sonnet (Anthropic)**   | 64.000               | Geração fluida e coerente     |\n| **Grok 3 Beta (xAI)**               | 16.384               | Respostas médias e rápidas    |\n| **DeepSeek R1 (DeepSeek)**          | 8.192                | Respostas curtas e econômicas |","x":8579,"y":-2282,"width":700,"height":260},
		{"id":"288f286730b7d2d9","type":"text","text":"- **Conceito de token:**\n    - O texto enviado a um LLM é **dividido em pequenas unidades chamadas tokens** (partes de palavras).\n    - O modelo processa e gera respostas com base nesses tokens, e não em palavras completas.\n","x":7640,"y":-2964,"width":807,"height":118},
		{"id":"d802d517f7f5d6d6","type":"text","text":"- **Definição da janela de contexto:**\n    - É a **quantidade máxima de tokens** que o modelo pode **processar em uma única interação** (entrada + saída).\n    - Quanto **maior a janela**, **mais informações** o modelo consegue considerar ao mesmo tempo.","x":7640,"y":-2838,"width":807,"height":117},
		{"id":"2ca24aa9e8876f58","type":"text","text":"- **Importância prática:**\n    - Modelos com janelas maiores conseguem **manter o contexto de conversas longas** ou **analisar textos extensos** sem perder detalhes.\n    - Ideal para tarefas como **análise de documentos grandes**, **atendimento contínuo** e **resumos contextuais**.","x":7640,"y":-2704,"width":803,"height":147},
		{"id":"6867e17f2f3f261f","type":"text","text":"- **Limites de uso:**\n    - Cada API impõe um **limite máximo de tokens por requisição**.\n    - Se o texto ultrapassar o limite, é necessário **dividir o conteúdo** ou **fazer várias chamadas** à API.\n    - Conhecer esses limites é essencial para **otimizar custos e evitar erros**.","x":7640,"y":-2539,"width":803,"height":130},
		{"id":"b67efebdba719b1c","type":"text","text":"#### Janela de Contexto","x":7240,"y":-2660,"width":227,"height":64},
		{"id":"0ab5edc0b6cf89e1","type":"text","text":"#### Máximo de _Tokens_ de Saída","x":7240,"y":-2227,"width":250,"height":79},
		{"id":"984f2280fa6676b6","type":"text","text":"3. **Solicitação de API**\n    - O LangChain, por meio do módulo **APIChain**, **gera automaticamente** uma requisição para a **API do servidor** (um serviço externo que contém as informações solicitadas).\n    ","x":6340,"y":-2855,"width":681,"height":120},
		{"id":"5b6a5e7de49a7167","type":"text","text":"4. **Resposta da API**\n    - O **servidor da API** processa o pedido e retorna uma **resposta estruturada** com os dados (por exemplo, uma lista de filmes de comédia).\n        \n","x":6340,"y":-2715,"width":681,"height":100},
		{"id":"b1fbee4663fbf823","type":"text","text":"5. **Processamento pelo LLM**\n    - O LangChain e o **LLM** processam a resposta recebida, **interpretam os dados** e os transformam em uma **resposta em linguagem natural**, compreensível para o usuário.\n        \n","x":6340,"y":-2595,"width":681,"height":120},
		{"id":"4717ad4c8229e889","type":"text","text":"6. **Retorno ao usuário**\n    - O sistema apresenta a resposta final, como:\n        1. _Se Beber, Não Case!_\n        2. _Debi & Loide_\n        3. _Meu Malvado Favorito_","x":6340,"y":-2455,"width":681,"height":140},
		{"id":"340019eb102604fd","type":"text","text":"#### _Chatbot_ Arena®","x":7240,"y":-1843,"width":204,"height":60},
		{"id":"092b145d7e0debee","type":"text","text":"#### Custo por 1 Milhão de _Tokens_","x":7240,"y":-1343,"width":226,"height":80},
		{"id":"9572ae129c9d5174","type":"text","text":"- **Definição:**\n    - O **Chatbot Arena®** é uma **plataforma de avaliação comparativa** que mede o **desempenho de modelos de LLM** em **conversas reais**.\n    - Avalia critérios como **qualidade das respostas**, **compreensão do contexto** e **fluidez textual**.\n        \n","x":7640,"y":-1903,"width":803,"height":120},
		{"id":"495ab6232d76f260","type":"text","text":"|Característica|Low-code|Codificação tradicional|\n|---|---|---|\n|**Habilidades**|Exige pouco conhecimento técnico|Requer programadores experientes|\n|**Custo**|Menor|Maior (infraestrutura e mão de obra)|\n|**Velocidade**|Desenvolvimento rápido|Desenvolvimento mais lento|\n|**Implantação**|Simples e automatizada|Mais complexa|\n|**Alcance**|Amplo (inclusive usuários não técnicos)|Restrito a profissionais de TI|","x":7423,"y":-712,"width":737,"height":206},
		{"id":"b4ae79c0783e3bad","type":"text","text":" **Função complementar do low-code**\n- **Não substitui o desenvolvimento tradicional**, mas **o complementa**.\n- Permite que:\n    - **Tarefas simples** sejam realizadas por não programadores.\n    - **Desenvolvedores experientes** foquem em **projetos avançados e personalizados**.\n    - A equipe de TI **aumente a produtividade** e **reduza retrabalho**","x":7478,"y":-446,"width":682,"height":199},
		{"id":"03408f85ba017085","type":"text","text":"- Exemplificação API\n![[ex_api.png]]","x":5400,"y":-2946,"width":720,"height":511},
		{"id":"abb4baeea89ae41a","type":"text","text":"### Comparativo de Plataformas de _APIs_ para _LLMs_","x":5698,"y":-2014,"width":343,"height":75},
		{"id":"ee6f5cc50c666f89","type":"text","text":"- As **APIs de LLMs** permitem acesso a modelos de linguagem sem necessidade de hospedagem local.\n    \n- Cada plataforma oferece **modelos com diferentes capacidades, custos e desempenho**.\n    \n- A comparação considera:\n    \n    - **Janela de contexto** (quantidade de tokens processáveis)\n        \n    - **Máximo de tokens de saída** (tamanho da resposta)\n        \n    - **Performance no Chatbot Arena®**\n        \n    - **Custo por milhão de tokens**","x":6198,"y":-2162,"width":723,"height":223},
		{"id":"3145ac49e2f1bf4b","type":"text","text":"![[api_comparacao.png]]","x":6276,"y":-1922,"width":723,"height":240},
		{"id":"4f6017516f3d9ab9","type":"text","text":"1. **Prompt do usuário**\n    - O processo começa quando o usuário envia uma **pergunta ou comando** para o sistema, por exemplo:  \n        _“Você pode me dizer os 3 melhores filmes de comédia de todos os tempos?”_\n    ","x":6340,"y":-3115,"width":681,"height":120},
		{"id":"7289937684709c92","type":"text","text":"2. **Envio da consulta ao LangChain**\n    - O **LangChain** recebe essa solicitação e a interpreta.\n    - Ele identifica que precisa consultar uma **API externa** para obter dados atualizados.\n        \n","x":6340,"y":-2975,"width":681,"height":98},
		{"id":"35a03dadb143bef6","type":"text","text":"1. O usuário envia um **prompt** a um **módulo de planejamento**, que cria um **fluxo de trabalho estruturado**.\n2. O usuário **edita o fluxo** usando operações visuais (clique, arrastar e soltar).\n3. Um **módulo de execução** interpreta o fluxo e gera a **resposta do LLM**.\n4. O usuário pode **refinar e ajustar** o fluxo até alcançar o resultado desejado.","x":6232,"y":-1263,"width":656,"height":209},
		{"id":"410c4d8b64f43cdb","type":"text","text":"**Desafio atual:**\n- LLMs são tecnologias complexas, exigindo **conhecimento em múltiplas linguagens**, **frameworks** e **gestão de infraestrutura**.\n- Isso torna a **integração com aplicativos tradicionalmente cara e demorada**.","x":4440,"y":-1250,"width":752,"height":144},
		{"id":"690977c8152142e4","type":"text","text":" **Surgimento das plataformas low-code**\n- **Definição:** ferramentas que permitem **criar aplicações com pouco ou nenhum código**, utilizando **interfaces visuais** e **componentes prontos**.\n- **Objetivo:** **simplificar** o desenvolvimento e **reduzir a dependência de programadores especializados**.\n    \n- **Tendência:**\n    - Segundo a **Gartner (2022)**, até **2026**, cerca de **80% dos desenvolvedores** que utilizam ferramentas low-code **não serão da área de TI** (em 2021 eram 60%).","x":4440,"y":-1086,"width":752,"height":240},
		{"id":"c51538a35b1a13f8","type":"text","text":" **Vantagens das plataformas low-code**\n- **Desenvolvimento rápido:** criação de **protótipos e produtos finais em menos tempo**.\n- **Integração facilitada:** permite **conectar LLMs via APIs** sem conhecimento profundo de IA.\n- **Interface intuitiva:** uso de **cliques, arrastar e soltar**, e **edição visual de fluxos** em vez de código.\n- **Acesso democratizado:** possibilita que **profissionais não técnicos** também criem soluções com LLMs.","x":4440,"y":-826,"width":752,"height":188},
		{"id":"bb43391961096dc6","type":"text","text":"- Visão geral da interação humana com _Large Language Models_ por meio de _low-code_ (_low-code_ LLM) e sua comparação com a interação convencional\n![[low_code.png]]","x":5360,"y":-1258,"width":792,"height":620},
		{"id":"487d9cd16187c326","type":"text","text":"![[low_convencional.png]]","x":6538,"y":-1006,"width":700,"height":971},
		{"id":"fa10d8fb5eb9994a","type":"text","text":" **Importância das APIs**\n- Muitas empresas **não possuem infraestrutura** ou recursos para hospedar um LLM localmente.\n- As **APIs** surgem como uma forma prática e acessível de **usar LLMs prontos** sem precisar gerenciar servidores complexos.\n- Funcionam como uma **ponte** entre a aplicação e o modelo:\n    - A aplicação envia um **pedido (prompt)**.\n    - O LLM processa e retorna uma **resposta gerada**.","x":4440,"y":-1985,"width":752,"height":224},
		{"id":"e62706b83c6d3c30","type":"text","text":" **Etapas do uso de um LLM via API**\n1. **Autenticação:** obter e configurar as **credenciais de acesso**.\n2. **Preparação da solicitação:** formatar o **texto ou prompt** de entrada.\n3. **Envio da solicitação:** enviar o prompt via **requisição HTTP**.\n4. **Processamento pelo LLM:** o modelo interpreta e gera uma **resposta em linguagem natural**.\n5. **Recebimento da resposta:** a aplicação obtém o **resultado da API**.\n6. **Integração final:** a resposta é **utilizada** dentro da aplicação (por exemplo, exibida ao usuário).","x":4440,"y":-1744,"width":752,"height":230},
		{"id":"e16030d0c3476ed6","type":"text","text":" **Propósito das plataformas low-code de agentes**\n- Permitem **criar e gerenciar agentes de IA baseados em LLMs** sem necessidade de programação avançada.\n- Tornam o desenvolvimento **mais rápido, acessível e visual**, atendendo tanto **desenvolvedores quanto usuários não técnicos**.\n    \n- Oferecem **interfaces intuitivas** e **componentes prontos** para construção de fluxos de trabalho e automação com IA.","x":5054,"y":-315,"width":752,"height":220},
		{"id":"7142f1c635420e56","type":"text","text":" **Critérios de comparação das plataformas**: As ferramentas são avaliadas segundo características de:\n- **Abordagem de programação:**\n    - _Ferramenta visual_ (arrastar e soltar blocos).\n    - _Integração via API_ (para programadores que desejam mais controle).\n- **LLMs suportadas:**\n    - _Modelos abertos e comerciais_ (maior flexibilidade).\n    - _Apenas modelos proprietários_ (restrição ao fornecedor).\n- **Preço:** gratuito (código aberto) ou apenas planos pagos.\n- **Suporte a RAG:** permite criar fluxos de _Retrieval-Augmented Generation_ visualmente.\n- **Suporte a agentes:** criação de agentes autônomos e interativos.\n- **_Single Sign-On_ (SSO) e controle de acesso**: permite que usuários acessem vários sistemas ou plataformas usando uma única credencial de login (por exemplo com contas do Google®). Controle de acesso são ferramentas que permitem limitar quem pode visualizar, editar ou executar diferentes partes dos sistemas, garantindo a segurança e a privacidade dos dados.\n- **Execução local**: define se usa ambiente local.\n- **Execução na nuvem:** define se pode ser usada em servidor online.","x":5054,"y":-80,"width":752,"height":440},
		{"id":"7545a19dd82784d0","type":"text","text":"* Comparação das principais soluções _low-code_ para construção de agentes\n![[solucoes_low.png]]","x":5870,"y":360,"width":816,"height":500},
		{"id":"ac649f61f7d4bcac","type":"text","text":"### Plataformas _Low-code_ para Integração de _LLMs_","x":4544,"y":-140,"width":322,"height":89},
		{"id":"dd5aed0e478da5e8","x":6836,"y":329,"width":804,"height":331,"type":"text","text":"Comparativo das principais ferramentas\n\n| Ferramenta                    | Tipo         | Código                      | Destaque                                                    |\n| ----------------------------- | ------------ | --------------------------- | ----------------------------------------------------------- |\n| **Dify®**                     | Visual + API | Aberto (comercial opcional) | Flexível, permite execução local e suporte a vários LLMs    |\n| **LangFlow®**                 | Visual       | Aberto                      | Interface intuitiva e suporte a RAG                         |\n| **Flowise®**                  | Visual       | Aberto                      | Simples, ideal para iniciantes em agentes LLM               |\n| **Google Vertex AI®**         | Comercial    | Proprietário                | Forte integração com ecossistema Google                     |\n| **Microsoft Copilot Studio®** | Comercial    | Proprietário                | Integração nativa com ferramentas Microsoft (Teams, Office) |\n"},
		{"id":"7e9769d39f54f015","x":7420,"y":700,"width":780,"height":260,"type":"text","text":" **Outras soluções relevantes**\n- **Galadon®:** apenas comercial; construção visual de chatbots.\n- **LLMStack®:** código aberto; cria fluxos de agentes com opção de hospedagem em nuvem.\n- **RAGFlow®:** especializado em _pipelines_ RAG; permite acesso a bases e documentos em tempo real.\n- **n8n®:** automação de fluxos com integração de LLMs (como OpenAI®); ideal para **tarefas operacionais**, **análise de dados** e **CRM**.\n- **CrewAI® (Brasil):** destaca-se pela **facilidade de criar agentes autônomos** integrados a fluxos low-code, mesmo por usuários sem experiência em programação."}
	],
	"edges":[
		{"id":"fdbce29d80c923d1","fromNode":"9c03cec79b9abce8","fromSide":"top","toNode":"2fbb270069221310","toSide":"left"},
		{"id":"1172eef6d6818574","fromNode":"2fbb270069221310","fromSide":"right","toNode":"3ac4aa4caf968ae0","toSide":"left"},
		{"id":"505f9ec6c286f8b8","fromNode":"2fbb270069221310","fromSide":"right","toNode":"b463bba0c4f9e5ee","toSide":"left"},
		{"id":"993ee35e47f2a031","fromNode":"85cc6196372e160a","fromSide":"right","toNode":"f1a3b028f89918e7","toSide":"left"},
		{"id":"7e0dbd5446917490","fromNode":"f1a3b028f89918e7","fromSide":"right","toNode":"1b3b62266ceea6d5","toSide":"left"},
		{"id":"fd5164ca1a71a4ff","fromNode":"f1a3b028f89918e7","fromSide":"right","toNode":"c8b85dc406f0b4db","toSide":"left"},
		{"id":"7e7257067b0c4257","fromNode":"f1a3b028f89918e7","fromSide":"right","toNode":"386696c56bd4b5b4","toSide":"left"},
		{"id":"2637fe3251e2ed49","fromNode":"386696c56bd4b5b4","fromSide":"right","toNode":"d5be64ff83fa15eb","toSide":"left","label":"+ práticas"},
		{"id":"b1f579be11b8555f","fromNode":"85cc6196372e160a","fromSide":"right","toNode":"d52c6352ff3989b1","toSide":"left"},
		{"id":"e31c8a9e28c5358a","fromNode":"d52c6352ff3989b1","fromSide":"right","toNode":"cc32d62a35e4182d","toSide":"left"},
		{"id":"94426bb350b7c319","fromNode":"d52c6352ff3989b1","fromSide":"right","toNode":"72482dc5e39728e8","toSide":"left"},
		{"id":"29fa7288efcb6f52","fromNode":"72482dc5e39728e8","fromSide":"right","toNode":"5ff28880d4e86573","toSide":"left"},
		{"id":"094dc952e4ef4a83","fromNode":"c8b85dc406f0b4db","fromSide":"right","toNode":"8283998a61868de1","toSide":"left"},
		{"id":"e40a18533779780b","fromNode":"3ac4aa4caf968ae0","fromSide":"right","toNode":"84a1e895d7a86c1f","toSide":"left"},
		{"id":"f5a4095ab078d9d3","fromNode":"3ac4aa4caf968ae0","fromSide":"right","toNode":"85cc6196372e160a","toSide":"left"},
		{"id":"16fd71c596194cd9","fromNode":"8283998a61868de1","fromSide":"right","toNode":"fa10d8fb5eb9994a","toSide":"left"},
		{"id":"71127198fb585d5c","fromNode":"b463bba0c4f9e5ee","fromSide":"right","toNode":"9c2fa95ead834469","toSide":"left"},
		{"id":"581b28ba6fca4011","fromNode":"b463bba0c4f9e5ee","fromSide":"right","toNode":"61d0af47454358d7","toSide":"left"},
		{"id":"ace8525f48ad8e85","fromNode":"8283998a61868de1","fromSide":"right","toNode":"e62706b83c6d3c30","toSide":"left"},
		{"id":"c8629f478513a080","fromNode":"e62706b83c6d3c30","fromSide":"right","toNode":"03408f85ba017085","toSide":"left"},
		{"id":"cfe9cff29539e58d","fromNode":"03408f85ba017085","fromSide":"right","toNode":"4f6017516f3d9ab9","toSide":"left"},
		{"id":"307e1aa39175e113","fromNode":"03408f85ba017085","fromSide":"right","toNode":"7289937684709c92","toSide":"left"},
		{"id":"529f4aaf0d5a95be","fromNode":"03408f85ba017085","fromSide":"right","toNode":"984f2280fa6676b6","toSide":"left"},
		{"id":"acc24b9d308ff531","fromNode":"03408f85ba017085","fromSide":"right","toNode":"5b6a5e7de49a7167","toSide":"left"},
		{"id":"a68aa8f363ec562b","fromNode":"03408f85ba017085","fromSide":"right","toNode":"b1fbee4663fbf823","toSide":"left"},
		{"id":"4a33e22dbbf73788","fromNode":"03408f85ba017085","fromSide":"right","toNode":"4717ad4c8229e889","toSide":"left"},
		{"id":"d86f6f3ccba80e34","fromNode":"e62706b83c6d3c30","fromSide":"right","toNode":"abb4baeea89ae41a","toSide":"left"},
		{"id":"da5a2ce71dfdae02","fromNode":"abb4baeea89ae41a","fromSide":"right","toNode":"3145ac49e2f1bf4b","toSide":"left"},
		{"id":"e1cf72bed92dd0c2","fromNode":"abb4baeea89ae41a","fromSide":"right","toNode":"ee6f5cc50c666f89","toSide":"left"},
		{"id":"348d68cbe554681a","fromNode":"3145ac49e2f1bf4b","fromSide":"right","toNode":"b67efebdba719b1c","toSide":"left"},
		{"id":"b9acd5351dda2315","fromNode":"3145ac49e2f1bf4b","fromSide":"right","toNode":"0ab5edc0b6cf89e1","toSide":"left"},
		{"id":"5dcb966775f875de","fromNode":"3145ac49e2f1bf4b","fromSide":"right","toNode":"340019eb102604fd","toSide":"left"},
		{"id":"0ce54429d737b94f","fromNode":"3145ac49e2f1bf4b","fromSide":"right","toNode":"092b145d7e0debee","toSide":"left"},
		{"id":"9e31cba4eba7bb1f","fromNode":"b67efebdba719b1c","fromSide":"right","toNode":"288f286730b7d2d9","toSide":"left"},
		{"id":"7b74fc08e0aa2ae8","fromNode":"b67efebdba719b1c","fromSide":"right","toNode":"d802d517f7f5d6d6","toSide":"left"},
		{"id":"c2394591ef151a68","fromNode":"b67efebdba719b1c","fromSide":"right","toNode":"2ca24aa9e8876f58","toSide":"left"},
		{"id":"4ea14a397dedd745","fromNode":"b67efebdba719b1c","fromSide":"right","toNode":"6867e17f2f3f261f","toSide":"left"},
		{"id":"7885d0bb3c9de183","fromNode":"288f286730b7d2d9","fromSide":"right","toNode":"33b1a8336066a3c1","toSide":"left"},
		{"id":"173b03feb5b833dd","fromNode":"2ca24aa9e8876f58","fromSide":"right","toNode":"685ca05af6bdcf4c","toSide":"left"},
		{"id":"fd8e091a1750b8c6","fromNode":"a6500630c37cd2be","fromSide":"right","toNode":"63851007ca1c58e9","toSide":"left"},
		{"id":"c68f56e19a9c14cb","fromNode":"0ab5edc0b6cf89e1","fromSide":"right","toNode":"3519913edaf4ad06","toSide":"left"},
		{"id":"3aa965091ef352aa","fromNode":"0ab5edc0b6cf89e1","fromSide":"right","toNode":"4afd0a06d45a6e83","toSide":"left"},
		{"id":"b1470f9f3a95a8e0","fromNode":"0ab5edc0b6cf89e1","fromSide":"right","toNode":"a6500630c37cd2be","toSide":"left"},
		{"id":"ff84b2b1e58688de","fromNode":"d13a14cdd7890ae8","fromSide":"right","toNode":"085056ca3f8c2b87","toSide":"left"},
		{"id":"5b7387b9548d0b4c","fromNode":"340019eb102604fd","fromSide":"right","toNode":"9572ae129c9d5174","toSide":"left"},
		{"id":"63379e7fcf18342a","fromNode":"340019eb102604fd","fromSide":"right","toNode":"b5e0deb1d605f15c","toSide":"left"},
		{"id":"dbf4a04e79adafdb","fromNode":"340019eb102604fd","fromSide":"right","toNode":"d13a14cdd7890ae8","toSide":"left"},
		{"id":"5e0f3c302da089ab","fromNode":"092b145d7e0debee","fromSide":"right","toNode":"f6366fe5e4f9cdd3","toSide":"left"},
		{"id":"edc87f7f89e27f7a","fromNode":"092b145d7e0debee","fromSide":"right","toNode":"b5cc347a4027767e","toSide":"left"},
		{"id":"9efc1a4ac09b2373","fromNode":"b5cc347a4027767e","fromSide":"right","toNode":"40e5032d08173b9d","toSide":"left"},
		{"id":"84d481784d4c4983","fromNode":"c8b85dc406f0b4db","fromSide":"right","toNode":"61bd20a38942338b","toSide":"left"},
		{"id":"6986773fede878aa","fromNode":"9c2fa95ead834469","fromSide":"right","toNode":"8211ffad4f170546","toSide":"left"},
		{"id":"af9fd7e586ab38b0","fromNode":"61bd20a38942338b","fromSide":"right","toNode":"410c4d8b64f43cdb","toSide":"left"},
		{"id":"36de2f7cef6ec0a7","fromNode":"61bd20a38942338b","fromSide":"right","toNode":"690977c8152142e4","toSide":"left"},
		{"id":"200c6ee58a1edad5","fromNode":"61bd20a38942338b","fromSide":"right","toNode":"c51538a35b1a13f8","toSide":"left"},
		{"id":"08f430e795a3a2a8","fromNode":"690977c8152142e4","fromSide":"right","toNode":"bb43391961096dc6","toSide":"left"},
		{"id":"a5be2d983c350aca","fromNode":"bb43391961096dc6","fromSide":"right","toNode":"35a03dadb143bef6","toSide":"left"},
		{"id":"60b7aa386fe9168d","fromNode":"bb43391961096dc6","fromSide":"right","toNode":"487d9cd16187c326","toSide":"left","label":"Low-code \nVS \ncodificação tradicional "},
		{"id":"05bed0ab34ca2c3f","fromNode":"487d9cd16187c326","fromSide":"right","toNode":"495ab6232d76f260","toSide":"left"},
		{"id":"81e1c64d1b6f3a5b","fromNode":"487d9cd16187c326","fromSide":"right","toNode":"b4ae79c0783e3bad","toSide":"left"},
		{"id":"f3cd3e3d9a1cdc75","fromNode":"61bd20a38942338b","fromSide":"right","toNode":"ac649f61f7d4bcac","toSide":"left"},
		{"id":"529cf8a002d32495","fromNode":"7142f1c635420e56","fromSide":"bottom","toNode":"7545a19dd82784d0","toSide":"left"},
		{"id":"3eb8a5a39e433453","fromNode":"ac649f61f7d4bcac","fromSide":"right","toNode":"e16030d0c3476ed6","toSide":"left"},
		{"id":"24332bfad9da4b16","fromNode":"ac649f61f7d4bcac","fromSide":"right","toNode":"7142f1c635420e56","toSide":"left"},
		{"id":"ca17f60eb908a788","fromNode":"7545a19dd82784d0","fromSide":"right","toNode":"dd5aed0e478da5e8","toSide":"left"},
		{"id":"546e4d3a906878a1","fromNode":"dd5aed0e478da5e8","fromSide":"bottom","toNode":"7e9769d39f54f015","toSide":"left"}
	]
}